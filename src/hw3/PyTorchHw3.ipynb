{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "cfT_QI8oisPD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 1: Создание Dataset\n",
        "class CaliforniaHousingDataset(Dataset):\n",
        "    def __init__(self, data, target):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.target[idx], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "I7OpfLkGi0Sq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "1ZVxS8pmi3wr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализация данных\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "gH2loOVei6jq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на train и test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
      ],
      "metadata": {
        "id": "i4D5utBTi8cF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание Dataset\n",
        "train_dataset = CaliforniaHousingDataset(X_train, y_train)\n",
        "test_dataset = CaliforniaHousingDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "lGtvRInLi-UF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 2: Обертка в DataLoader\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "QH039G09jAI4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 3 и 4: Архитектура сети с BatchNorm и Dropout\n",
        "class CaliforniaHousingModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_rate=0.2):\n",
        "        super(CaliforniaHousingModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size1) # BatchNorm1d слой\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_rate) # Dropout слой\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size2) # BatchNorm1d слой\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_rate) # Dropout слой\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "skZFmLpRjChc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 6: Обучение и сравнение сходимости\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=50):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "3GfxbOhAjI0U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 7: Обучение и оценка моделей\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 64\n",
        "hidden_size2 = 32\n",
        "output_size = 1\n",
        "dropout_rate = 0.2"
      ],
      "metadata": {
        "id": "FMWWobcmjQPE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam\n",
        "model_adam = CaliforniaHousingModel(input_size, hidden_size1, hidden_size2, output_size, dropout_rate)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001)\n",
        "train_model(model_adam, train_dataloader, criterion, optimizer_adam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7wBWI5PjWbD",
        "outputId": "2ab3d42a-5be7-4fbb-ee8a-df78a9a1c465"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 1.7981\n",
            "Epoch [2/50], Loss: 0.6503\n",
            "Epoch [3/50], Loss: 0.5785\n",
            "Epoch [4/50], Loss: 0.5363\n",
            "Epoch [5/50], Loss: 0.5163\n",
            "Epoch [6/50], Loss: 0.5010\n",
            "Epoch [7/50], Loss: 0.5025\n",
            "Epoch [8/50], Loss: 0.4874\n",
            "Epoch [9/50], Loss: 0.4659\n",
            "Epoch [10/50], Loss: 0.4650\n",
            "Epoch [11/50], Loss: 0.4555\n",
            "Epoch [12/50], Loss: 0.4424\n",
            "Epoch [13/50], Loss: 0.4318\n",
            "Epoch [14/50], Loss: 0.4267\n",
            "Epoch [15/50], Loss: 0.4169\n",
            "Epoch [16/50], Loss: 0.4173\n",
            "Epoch [17/50], Loss: 0.4186\n",
            "Epoch [18/50], Loss: 0.4196\n",
            "Epoch [19/50], Loss: 0.4108\n",
            "Epoch [20/50], Loss: 0.4131\n",
            "Epoch [21/50], Loss: 0.4073\n",
            "Epoch [22/50], Loss: 0.4068\n",
            "Epoch [23/50], Loss: 0.4017\n",
            "Epoch [24/50], Loss: 0.4045\n",
            "Epoch [25/50], Loss: 0.3955\n",
            "Epoch [26/50], Loss: 0.3980\n",
            "Epoch [27/50], Loss: 0.3957\n",
            "Epoch [28/50], Loss: 0.4013\n",
            "Epoch [29/50], Loss: 0.3963\n",
            "Epoch [30/50], Loss: 0.3909\n",
            "Epoch [31/50], Loss: 0.3916\n",
            "Epoch [32/50], Loss: 0.3916\n",
            "Epoch [33/50], Loss: 0.3926\n",
            "Epoch [34/50], Loss: 0.3846\n",
            "Epoch [35/50], Loss: 0.3901\n",
            "Epoch [36/50], Loss: 0.3854\n",
            "Epoch [37/50], Loss: 0.3846\n",
            "Epoch [38/50], Loss: 0.3840\n",
            "Epoch [39/50], Loss: 0.3795\n",
            "Epoch [40/50], Loss: 0.3846\n",
            "Epoch [41/50], Loss: 0.3855\n",
            "Epoch [42/50], Loss: 0.3842\n",
            "Epoch [43/50], Loss: 0.3757\n",
            "Epoch [44/50], Loss: 0.3888\n",
            "Epoch [45/50], Loss: 0.3858\n",
            "Epoch [46/50], Loss: 0.3775\n",
            "Epoch [47/50], Loss: 0.3804\n",
            "Epoch [48/50], Loss: 0.3822\n",
            "Epoch [49/50], Loss: 0.3797\n",
            "Epoch [50/50], Loss: 0.3766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSProp\n",
        "model_rmsprop = CaliforniaHousingModel(input_size, hidden_size1, hidden_size2, output_size, dropout_rate)\n",
        "optimizer_rmsprop = optim.RMSprop(model_rmsprop.parameters(), lr=0.001)\n",
        "train_model(model_rmsprop, train_dataloader, criterion, optimizer_rmsprop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B_f5bgJjcbU",
        "outputId": "2d26d290-96d4-467f-94bf-fea1f3131df7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.8423\n",
            "Epoch [2/50], Loss: 0.5871\n",
            "Epoch [3/50], Loss: 0.5454\n",
            "Epoch [4/50], Loss: 0.5100\n",
            "Epoch [5/50], Loss: 0.4931\n",
            "Epoch [6/50], Loss: 0.4675\n",
            "Epoch [7/50], Loss: 0.4558\n",
            "Epoch [8/50], Loss: 0.4496\n",
            "Epoch [9/50], Loss: 0.4321\n",
            "Epoch [10/50], Loss: 0.4261\n",
            "Epoch [11/50], Loss: 0.4272\n",
            "Epoch [12/50], Loss: 0.4203\n",
            "Epoch [13/50], Loss: 0.4064\n",
            "Epoch [14/50], Loss: 0.4096\n",
            "Epoch [15/50], Loss: 0.4056\n",
            "Epoch [16/50], Loss: 0.4048\n",
            "Epoch [17/50], Loss: 0.4002\n",
            "Epoch [18/50], Loss: 0.3940\n",
            "Epoch [19/50], Loss: 0.3925\n",
            "Epoch [20/50], Loss: 0.3951\n",
            "Epoch [21/50], Loss: 0.3907\n",
            "Epoch [22/50], Loss: 0.3851\n",
            "Epoch [23/50], Loss: 0.3904\n",
            "Epoch [24/50], Loss: 0.3860\n",
            "Epoch [25/50], Loss: 0.3843\n",
            "Epoch [26/50], Loss: 0.3858\n",
            "Epoch [27/50], Loss: 0.3847\n",
            "Epoch [28/50], Loss: 0.3897\n",
            "Epoch [29/50], Loss: 0.3894\n",
            "Epoch [30/50], Loss: 0.3848\n",
            "Epoch [31/50], Loss: 0.3766\n",
            "Epoch [32/50], Loss: 0.3780\n",
            "Epoch [33/50], Loss: 0.3841\n",
            "Epoch [34/50], Loss: 0.3812\n",
            "Epoch [35/50], Loss: 0.3776\n",
            "Epoch [36/50], Loss: 0.3798\n",
            "Epoch [37/50], Loss: 0.3774\n",
            "Epoch [38/50], Loss: 0.3740\n",
            "Epoch [39/50], Loss: 0.3740\n",
            "Epoch [40/50], Loss: 0.3779\n",
            "Epoch [41/50], Loss: 0.3762\n",
            "Epoch [42/50], Loss: 0.3748\n",
            "Epoch [43/50], Loss: 0.3789\n",
            "Epoch [44/50], Loss: 0.3682\n",
            "Epoch [45/50], Loss: 0.3766\n",
            "Epoch [46/50], Loss: 0.3704\n",
            "Epoch [47/50], Loss: 0.3704\n",
            "Epoch [48/50], Loss: 0.3739\n",
            "Epoch [49/50], Loss: 0.3705\n",
            "Epoch [50/50], Loss: 0.3690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD\n",
        "model_sgd = CaliforniaHousingModel(input_size, hidden_size1, hidden_size2, output_size, dropout_rate)\n",
        "optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=0.001, momentum=0.9)\n",
        "train_model(model_sgd, train_dataloader, criterion, optimizer_sgd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1VkuCgDjpoZ",
        "outputId": "9aaf7ce9-92ad-4f1e-b734-1e3401f4d023"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.8993\n",
            "Epoch [2/50], Loss: 0.6015\n",
            "Epoch [3/50], Loss: 0.5572\n",
            "Epoch [4/50], Loss: 0.5278\n",
            "Epoch [5/50], Loss: 0.5102\n",
            "Epoch [6/50], Loss: 0.4911\n",
            "Epoch [7/50], Loss: 0.4943\n",
            "Epoch [8/50], Loss: 0.4686\n",
            "Epoch [9/50], Loss: 0.4762\n",
            "Epoch [10/50], Loss: 0.4593\n",
            "Epoch [11/50], Loss: 0.4598\n",
            "Epoch [12/50], Loss: 0.4522\n",
            "Epoch [13/50], Loss: 0.4477\n",
            "Epoch [14/50], Loss: 0.4424\n",
            "Epoch [15/50], Loss: 0.4331\n",
            "Epoch [16/50], Loss: 0.4374\n",
            "Epoch [17/50], Loss: 0.4342\n",
            "Epoch [18/50], Loss: 0.4271\n",
            "Epoch [19/50], Loss: 0.4217\n",
            "Epoch [20/50], Loss: 0.4239\n",
            "Epoch [21/50], Loss: 0.4307\n",
            "Epoch [22/50], Loss: 0.4292\n",
            "Epoch [23/50], Loss: 0.4256\n",
            "Epoch [24/50], Loss: 0.4211\n",
            "Epoch [25/50], Loss: 0.4194\n",
            "Epoch [26/50], Loss: 0.4199\n",
            "Epoch [27/50], Loss: 0.4190\n",
            "Epoch [28/50], Loss: 0.4197\n",
            "Epoch [29/50], Loss: 0.4203\n",
            "Epoch [30/50], Loss: 0.4160\n",
            "Epoch [31/50], Loss: 0.4166\n",
            "Epoch [32/50], Loss: 0.4148\n",
            "Epoch [33/50], Loss: 0.4173\n",
            "Epoch [34/50], Loss: 0.4114\n",
            "Epoch [35/50], Loss: 0.4099\n",
            "Epoch [36/50], Loss: 0.4109\n",
            "Epoch [37/50], Loss: 0.4052\n",
            "Epoch [38/50], Loss: 0.4044\n",
            "Epoch [39/50], Loss: 0.4043\n",
            "Epoch [40/50], Loss: 0.4137\n",
            "Epoch [41/50], Loss: 0.4086\n",
            "Epoch [42/50], Loss: 0.4050\n",
            "Epoch [43/50], Loss: 0.4089\n",
            "Epoch [44/50], Loss: 0.4026\n",
            "Epoch [45/50], Loss: 0.3995\n",
            "Epoch [46/50], Loss: 0.4016\n",
            "Epoch [47/50], Loss: 0.4029\n",
            "Epoch [48/50], Loss: 0.3987\n",
            "Epoch [49/50], Loss: 0.3953\n",
            "Epoch [50/50], Loss: 0.4016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка качества моделей на тестовых данных\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), targets)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "    mean_loss = total_loss / len(dataloader.dataset)\n",
        "    return mean_loss"
      ],
      "metadata": {
        "id": "qKVPX_2xj0Fu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation on test data:\")\n",
        "loss_adam = evaluate_model(model_adam, test_dataloader)\n",
        "loss_rmsprop = evaluate_model(model_rmsprop, test_dataloader)\n",
        "loss_sgd = evaluate_model(model_sgd, test_dataloader)\n",
        "\n",
        "print(f\"Adam: {loss_adam:.4f}\")\n",
        "print(f\"RMSProp: {loss_rmsprop:.4f}\")\n",
        "print(f\"SGD: {loss_sgd:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVg6hpFgj48G",
        "outputId": "0e85d5e2-7789-4ecf-b8ae-8de6f5a373f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test data:\n",
            "Adam: 0.3477\n",
            "RMSProp: 0.5025\n",
            "SGD: 0.6508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы:\n",
        "\n",
        "На основании предоставленных данных о тренировке и тестировании моделей с использованием различных оптимизаторов (Adam, RMSProp, SGD), можно сделать следующие выводы:\n",
        "\n",
        "1. Сходимость моделей:\n",
        "   - Adam: Модель обучалась быстрее и достигла более низкой ошибки уже к 50-й эпохе. Значение функции потерь уменьшалось почти равномерно с каждой эпохой.\n",
        "   - RMSProp: Модель также достигла низкой ошибки, но обучалась медленнее по сравнению с Adam. Значение функции потерь немного скачкообразно снижалось в начале, но потом стало уменьшаться более стабильно.\n",
        "   - SGD: Модель также показала схожую сходимость, но процесс обучения был более нестабильным, и в начале значения функции потерь могли сильно скачать. Однако со временем процесс стабилизировался, и функция потерь снижалась.\n",
        "\n",
        "2. Качество предсказаний на тестовых данных:\n",
        "   - Модель, обученная с помощью Adam, показала лучший результат с наименьшей ошибкой (loss_adam = 0.3477) на тестовых данных. Это свидетельствует о хорошей обобщающей способности этой модели.\n",
        "   - Модель, обученная с помощью RMSProp, также показала хорошие результаты с низкой ошибкой (loss_rmsprop = 0.5025) на тестовых данных, но она была немного выше, чем у модели Adam.\n",
        "   - Модель, обученная с помощью SGD, показала наихудший результат с более высокой ошибкой (loss_sgd = 0.6508) на тестовых данных. Возможно, этот оптимизатор требует тщательной настройки гиперпараметров или более длительного обучения.\n",
        "\n",
        "3. Вывод:\n",
        "   - Из результатов можно сделать вывод, что Adam и RMSProp показывают хорошие результаты на этой задаче, но Adam обучается быстрее и дает более низкую ошибку на тестовых данных.\n",
        "   - SGD также дает приемлемый результат, но требует более тщательной настройки и может потребовать более длительного обучения для достижения схожего качества с Adam и RMSProp.\n",
        "\n",
        "Cтоит отметить, что результаты могут немного различаться в каждом запуске из-за случайной инициализации параметров моделей и случайности в данных при использовании SGD."
      ],
      "metadata": {
        "id": "UfqCs5iRj_Gk"
      }
    }
  ]
}